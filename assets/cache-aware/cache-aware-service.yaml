# Production Cache-Aware Service with Session Affinity
# Enables 2-hour client stickiness for optimal cache performance
apiVersion: v1
kind: Service
metadata:
  name: llama-3-2-1b-cache-aware-service
  namespace: llm-d
  labels:
    llmd.ai/gather-metrics: "true"
    app: cache-aware
spec:
  selector:
    llm-d.ai/role: decode
    llm-d.ai/model: llama-3-2-1b
  ports:
  - name: vllm-proxy
    port: 8000
    protocol: TCP
    targetPort: 8000
  - name: vllm
    port: 8001
    protocol: TCP
    targetPort: 8001
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 7200  # 2 hours
  type: ClusterIP
