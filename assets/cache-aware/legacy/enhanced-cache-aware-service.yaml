apiVersion: v1
kind: Service
metadata:
  name: llama-3-2-1b-cache-aware-service-enhanced
  namespace: llm-d
  labels:
    app: cache-aware-enhanced
    llmd.ai/gather-metrics: "true"
spec:
  type: ClusterIP
  ports:
  - name: vllm-proxy
    port: 8000
    protocol: TCP
    targetPort: 8000
  - name: vllm-direct
    port: 8001
    protocol: TCP
    targetPort: 8001
  - name: metrics
    port: 8002
    protocol: TCP
    targetPort: 8002
  selector:
    llm-d.ai/model: llama-3-2-1b
    llm-d.ai/role: decode
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600

