apiVersion: v1
kind: Service
metadata:
  name: llama-3-2-1b-cache-aware-service
  namespace: llm-d
  labels:
    app: cache-aware
    llmd.ai/gather-metrics: "true"
spec:
  type: ClusterIP
  ports:
  - name: vllm-proxy
    port: 8000
    protocol: TCP
    targetPort: 8000
  - name: vllm
    port: 8001
    protocol: TCP
    targetPort: 8001
  selector:
    llm-d.ai/model: llama-3-2-1b
    llm-d.ai/role: decode
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 7200

