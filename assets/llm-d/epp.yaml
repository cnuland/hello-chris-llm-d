apiVersion: v1
kind: ServiceAccount
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
rules:
- apiGroups: ["inference.networking.x-k8s.io"]
  resources: ["inferencemodels","inferencepools"]
  verbs: ["get","list","watch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get","list","watch"]
- apiGroups: ["discovery.k8s.io"]
  resources: ["endpointslices"]
  verbs: ["get","list","watch"]
- apiGroups: ["authentication.k8s.io"]
  resources: ["tokenreviews"]
  verbs: ["create"]
- apiGroups: ["authorization.k8s.io"]
  resources: ["subjectaccessreviews"]
  verbs: ["create"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ms-llm-d-modelservice-epp
subjects:
- kind: ServiceAccount
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
data:
  default-config.yaml: |
    apiVersion: inference.networking.x-k8s.io/v1alpha1
    kind: EndpointPickerConfig
    plugins:
    - type: prefix-cache-scorer
      parameters:
        hashBlockSize: 16
        maxPrefixBlocksToMatch: 256
        lruCapacityPerServer: 31250
    - type: decode-filter
    - type: max-score-picker
    - type: single-profile-handler
    schedulingProfiles:
    - name: default
      plugins:
      - pluginRef: decode-filter
      - pluginRef: max-score-picker
      - pluginRef: prefix-cache-scorer
        weight: 50
---
apiVersion: v1
kind: Service
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
spec:
  selector:
    llm-d.ai/epp: ms-llm-d-modelservice-epp
  ports:
  - name: grpc-ext-proc
    port: 9002
    targetPort: 9002
    protocol: TCP
    appProtocol: http2
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
spec:
  replicas: 1
  selector:
    matchLabels:
      llm-d.ai/epp: ms-llm-d-modelservice-epp
  template:
    metadata:
      labels:
        llm-d.ai/epp: ms-llm-d-modelservice-epp
    spec:
      serviceAccountName: ms-llm-d-modelservice-epp
      containers:
      - name: epp
        image: ghcr.io/llm-d/llm-d-inference-scheduler:v0.2.1
        imagePullPolicy: Always
        args:
        - --poolName
        - llm-d
        - --poolNamespace
        - llm-d
        - -v
        - "4"
        - --zap-encoder
        - json
        - --grpcPort
        - "9002"
        - --grpcHealthPort
        - "9003"
        - -configFile
        - config/default-config.yaml
        ports:
        - containerPort: 9002
          name: grpc
        - containerPort: 9003
          name: grpc-health
        - containerPort: 9090
          name: metrics
        readinessProbe:
          grpc:
            port: 9003
            service: envoy.service.ext_proc.v3.ExternalProcessor
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 1
        livenessProbe:
          grpc:
            port: 9003
            service: envoy.service.ext_proc.v3.ExternalProcessor
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 1
        volumeMounts:
        - name: plugins-config-volume
          mountPath: /config
      volumes:
      - name: plugins-config-volume
        configMap:
          name: ms-llm-d-modelservice-epp

