apiVersion: v1
kind: ServiceAccount
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
rules:
- apiGroups: ["inference.networking.x-k8s.io"]
  resources: ["inferencemodels","inferencepools"]
  verbs: ["get","list","watch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get","list","watch"]
- apiGroups: ["discovery.k8s.io"]
  resources: ["endpointslices"]
  verbs: ["get","list","watch"]
- apiGroups: ["authentication.k8s.io"]
  resources: ["tokenreviews"]
  verbs: ["create"]
- apiGroups: ["authorization.k8s.io"]
  resources: ["subjectaccessreviews"]
  verbs: ["create"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ms-llm-d-modelservice-epp
subjects:
- kind: ServiceAccount
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
data:
  default-config.yaml: |
    apiVersion: inference.networking.x-k8s.io/v1alpha1
    kind: EndpointPickerConfig
    plugins:
    - type: prefix-cache-scorer
      parameters:
        # Switch to tracking mode with explicit token processor and KV block index configs
        mode: cache_tracking
        tokenProcessorConfig:
          blockSize: 16
          hashSeed: "42"
        kvBlockIndexConfig:
          enableMetrics: true
          metricsLoggingInterval: 60000000000  # 60s in nanoseconds
        hashBlockSize: 16
        maxPrefixBlocksToMatch: 256
        lruCapacityPerServer: 31250
    - type: decode-filter
    - type: max-score-picker
    - type: single-profile-handler
      parameters:
        # Emit the chosen upstream endpoint so the gateway Lua filter can override routing.
        # Expected value: "<ip-or-host>:<port>" of the decode pod selected by the picker.
        # The Envoy Lua filter will copy this into x-envoy-upstream-override-host if needed,
        # but we also emit the override header directly for compatibility.
        selectedEndpointHeader: x-gateway-destination-endpoint
        selectedOverrideHeader: x-envoy-upstream-override-host
    schedulingProfiles:
    - name: default
      plugins:
      - pluginRef: decode-filter
      - pluginRef: prefix-cache-scorer
        weight: 90
      - pluginRef: max-score-picker
---
apiVersion: v1
kind: Service
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
spec:
  selector:
    llm-d.ai/epp: ms-llm-d-modelservice-epp
  ports:
  - name: grpc-ext-proc
    port: 9002
    targetPort: 9002
    protocol: TCP
    appProtocol: http2
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ms-llm-d-modelservice-epp
  namespace: llm-d
spec:
  replicas: 1
  selector:
    matchLabels:
      llm-d.ai/epp: ms-llm-d-modelservice-epp
  template:
    metadata:
      labels:
        llm-d.ai/epp: ms-llm-d-modelservice-epp
      annotations:
        sidecar.istio.io/inject: "false"
    spec:
      serviceAccountName: ms-llm-d-modelservice-epp
      containers:
      - name: epp
        image: ghcr.io/llm-d/llm-d-inference-scheduler:v0.2.1
        imagePullPolicy: Always
        args:
        - -v
        - "4"
        - --zap-encoder
        - json
        - --grpcPort
        - "9002"
        - --grpcHealthPort
        - "9003"
        - --secureServing
        - "false"
        - -poolName=llm-d
        - -poolNamespace=llm-d
        - -poolAPIVersion=inference.networking.x-k8s.io/v1alpha2
        - -configFile
        - /config/default-config.yaml
        ports:
        - containerPort: 9002
          name: grpc
        - containerPort: 9003
          name: grpc-health
        - containerPort: 9090
          name: metrics
        readinessProbe:
          grpc:
            port: 9003
            service: envoy.service.ext_proc.v3.ExternalProcessor
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 1
        livenessProbe:
          grpc:
            port: 9003
            service: envoy.service.ext_proc.v3.ExternalProcessor
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 1
        volumeMounts:
        - name: plugins-config-volume
          mountPath: /config
      - name: debug
        image: nicolaka/netshoot:latest
        imagePullPolicy: IfNotPresent
        command: ["bash","-lc","echo debug sidecar ready; sleep 31536000"]
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
      volumes:
      - name: plugins-config-volume
        configMap:
          name: ms-llm-d-modelservice-epp

