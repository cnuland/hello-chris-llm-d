apiVersion: llm-d.ai/v1alpha1
kind: ModelService
metadata:
  name: llama-3-2-3b-instruct
  namespace: llm-d
  labels:
    app.kubernetes.io/name: cache-aware-routing
    version: v0.2.0
spec:
  modelArtifacts:
    uri: "hf://meta-llama/Llama-3.2-3B-Instruct"
    size: 50Gi
    authSecretName: "llm-d-hf-token"

  routing:
    modelName: meta-llama/Llama-3.2-3B-Instruct
    ports:
    - name: inference
      port: 8000
    gatewayRefs:
    - group: gateway.networking.k8s.io
      kind: Gateway
      name: llm-d-gateway
      namespace: llm-d

  decode:
    replicas: 3
    acceleratorTypes:
      labelKey: nvidia.com/gpu.present
      labelValues:
      - "true"
    containers:
    - name: vllm
      image: ghcr.io/llm-d/llm-d:v0.2.0
      args:
        - "--enable-prefix-caching"
        - "--prefix-caching-hash-algo=builtin"
        - "--block-size=16"
        - "--gpu-memory-utilization=0.7"
        - "--max-model-len=4096"
        - "--no-enable-chunked-prefill"
        - "--kv-cache-dtype=auto"
        - "--max-num-seqs=256"
        - "--enforce-eager"
        - "--kv-transfer-config={\"kv_connector\":\"NixlConnector\", \"kv_role\":\"kv_both\"}"
      env:
      - name: VLLM_NIXL_SIDE_CHANNEL_HOST
        valueFrom:
          fieldRef:
            fieldPath: status.podIP
      - name: VLLM_NIXL_SIDE_CHANNEL_PORT
        value: "5557"
      - name: PYTHONHASHSEED
        value: "42"
      - name: HF_TOKEN
        valueFrom:
          secretKeyRef:
            key: HF_TOKEN
            name: llm-d-hf-token
      resources:
        limits:
          nvidia.com/gpu: "1"
        requests:
          nvidia.com/gpu: "1"
      mountModelVolume: true

  prefill:
    replicas: 1
    containers:
    - name: vllm
      image: ghcr.io/llm-d/llm-d:v0.2.0
      args:
        - "--enforce-eager"
        - "--kv-transfer-config={\"kv_connector\":\"NixlConnector\", \"kv_role\":\"kv_both\"}"
        - "--max-model-len=4096"
        - "--max-num-seqs=32"
      env:
      - name: VLLM_NIXL_SIDE_CHANNEL_HOST
        valueFrom:
          fieldRef:
            fieldPath: status.podIP
      - name: VLLM_NIXL_SIDE_CHANNEL_PORT
        value: "5557"
      - name: PYTHONHASHSEED
        value: "42"
      - name: HF_TOKEN
        valueFrom:
          secretKeyRef:
            key: HF_TOKEN
            name: llm-d-hf-token
      resources:
        limits:
          nvidia.com/gpu: "1"
        requests:
          nvidia.com/gpu: "1"
      mountModelVolume: true
