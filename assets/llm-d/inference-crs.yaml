apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferencePool
metadata:
  name: llm-d
  namespace: llm-d
spec:
  selector:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/role: decode
  targetPortNumber: 8000
  extensionRef:
    name: llama-3-2-3b-instruct
---
apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceModel
metadata:
  name: llama-3-2-3b-instruct
  namespace: llm-d
spec:
  poolRef:
    name: llm-d
  modelName: meta-llama/Llama-3.2-3B-Instruct

