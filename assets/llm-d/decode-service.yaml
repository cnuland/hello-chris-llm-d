apiVersion: v1
kind: Service
metadata:
  name: ms-llm-d-modelservice-decode
  namespace: llm-d
  labels:
    app.kubernetes.io/name: llm-d-demo
    llm-d.ai/role: decode
spec:
  selector:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: ms-llm-d-modelservice
    llm-d.ai/role: decode
  ports:
    - name: http
      port: 8000
      targetPort: 8000
      protocol: TCP

