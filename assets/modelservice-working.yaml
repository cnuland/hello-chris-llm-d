apiVersion: llm-d.ai/v1alpha1
kind: ModelService
metadata:
  annotations:
    config-refresh: "1754331044"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"llm-d.ai/v1alpha1","kind":"ModelService","metadata":{"annotations":{},"name":"llama-3-2-1b","namespace":"llm-d"},"spec":{"baseConfigMapRef":{"name":"basic-gpu-with-hybrid-cache"},"decode":{"acceleratorTypes":{"labelKey":"nvidia.com/gpu.present","labelValues":["true"]},"containers":[{"env":[{"name":"HF_TOKEN","valueFrom":{"secretKeyRef":{"key":"HF_TOKEN","name":"llm-d-hf-token"}}}],"name":"vllm","resources":{"limits":{"nvidia.com/gpu":"1"},"requests":{"nvidia.com/gpu":"1"}}}],"replicas":3},"modelArtifacts":{"authSecretName":"llm-d-hf-token","size":"50Gi","uri":"hf://meta-llama/Llama-3.2-1B"},"prefill":{"containers":[{"env":[{"name":"HF_TOKEN","valueFrom":{"secretKeyRef":{"key":"HF_TOKEN","name":"llm-d-hf-token"}}}],"name":"vllm"}],"replicas":2},"routing":{"gatewayRefs":[{"group":"gateway.networking.k8s.io","kind":"Gateway","name":"llm-d-gateway","namespace":"llm-d"}],"modelName":"llama-3-2-1b"}}}
  name: llama-3-2-1b
  namespace: llm-d
spec:
  baseConfigMapRef:
    name: basic-gpu-with-hybrid-cache
  decode:
    acceleratorTypes:
      labelKey: nvidia.com/gpu.present
      labelValues:
      - "true"
    containers:
    - env:
      - name: HF_TOKEN
        valueFrom:
          secretKeyRef:
            key: HF_TOKEN
            name: llm-d-hf-token
      name: vllm
      resources:
        limits:
          nvidia.com/gpu: "1"
        requests:
          nvidia.com/gpu: "1"
    replicas: 3
  modelArtifacts:
    authSecretName: llm-d-hf-token
    size: 50Gi
    uri: hf://meta-llama/Llama-3.2-1B
  prefill:
    containers:
    - env:
      - name: HF_TOKEN
        valueFrom:
          secretKeyRef:
            key: HF_TOKEN
            name: llm-d-hf-token
      name: vllm
    replicas: 2
  routing:
    gatewayRefs:
    - group: gateway.networking.k8s.io
      kind: Gateway
      name: llm-d-gateway
      namespace: llm-d
    modelName: llama-3-2-1b
  conditions:
  - lastTransitionTime: "2025-08-04T18:12:22Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    type: PrefillAvailable
  - lastTransitionTime: "2025-08-05T01:49:22Z"
    message: ReplicaSet "llama-3-2-1b-prefill-dd9b6f698" has timed out progressing.
    reason: ProgressDeadlineExceeded
    type: PrefillProgressing
  - lastTransitionTime: "2025-08-04T18:17:02Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    type: DecodeAvailable
  - lastTransitionTime: "2025-08-05T02:45:56Z"
    message: ReplicaSet "llama-3-2-1b-decode-67f7dbcc6b" has successfully progressed.
    reason: NewReplicaSetAvailable
    type: DecodeProgressing
  - lastTransitionTime: "2025-08-04T18:10:57Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    type: EppAvailable
  - lastTransitionTime: "2025-08-05T01:39:34Z"
    message: ReplicaSet "llama-3-2-1b-epp-6f8d695ff4" has successfully progressed.
    reason: NewReplicaSetAvailable
    type: EppProgressing
  decodeAvailable: 3
  decodeDeploymentRef: llama-3-2-1b-decode
  decodeReady: 3/3
  eppAvailable: 1
  eppDeploymentRef: llama-3-2-1b-epp
  eppReady: 1/1
  eppRoleBinding: llama-3-2-1b-epp-rolebinding
  httpRouteRef: llama-3-2-1b-http-route
  inferenceModelRef: llama-3-2-1b
  inferencePoolRef: llama-3-2-1b-inference-pool
  prefillAvailable: 2
  prefillDeploymentRef: llama-3-2-1b-prefill
  prefillReady: 2/2
  prefillServiceAccountRef: llama-3-2-1b-epp-sa
