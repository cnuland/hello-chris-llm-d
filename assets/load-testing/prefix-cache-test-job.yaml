apiVersion: batch/v1
kind: Job
metadata:
  name: prefix-cache-test
  namespace: llm-d
spec:
  template:
    spec:
      containers:
      - name: cache-test
        image: curlimages/curl:latest
        command: ["/bin/sh"]
        args:
        - -c
        - |
          echo "Starting prefix cache test with identical requests..."
          echo "Sending 10 identical requests in sequence to test caching"
          for i in $(seq 1 10); do
            echo "Request $i:"
            curl -s -X POST "http://llama-3-2-1b-decode-service.llm-d.svc.cluster.local:8000/v1/completions" \
              -H "Content-Type: application/json" \
              -d '{"model": "meta-llama/Llama-3.2-1B", "prompt": "What is artificial intelligence? Explain in detail.", "max_tokens": 50}' \
              -w "Status: %{http_code}, TTFB: %{time_starttransfer}s, Total: %{time_total}s\n" | tail -1
            sleep 2
          done
          echo "Prefix cache test completed - 10 identical requests sent"
      restartPolicy: Never
  backoffLimit: 3
