apiVersion: v1
items:
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-07-30T21:19:04Z"
    labels:
      app.kubernetes.io/component: decode
      llm-d.ai/model: llama-3-2-1b
      llm-d.ai/role: decode
    name: llama-3-2-1b-decode-metrics
    namespace: llm-d
    resourceVersion: "4468823"
    uid: 3b451cde-93e7-43ac-bdd2-55668ac02c4b
  spec:
    clusterIP: 172.30.24.190
    clusterIPs:
    - 172.30.24.190
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: metrics
      port: 8000
      protocol: TCP
      targetPort: 8000
    selector:
      llm-d.ai/inferenceServing: "true"
      llm-d.ai/model: llama-3-2-1b
      llm-d.ai/role: decode
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"llm-d.ai/model":"llama-3-2-1b","llm-d.ai/role":"decode"},"name":"llama-3-2-1b-decode-service","namespace":"llm-d"},"spec":{"ports":[{"name":"vllm","port":8000,"protocol":"TCP","targetPort":8000},{"name":"nixl","port":5557,"protocol":"TCP","targetPort":5557}],"selector":{"llm-d.ai/inferenceServing":"true","llm-d.ai/model":"llama-3-2-1b","llm-d.ai/role":"decode"},"type":"ClusterIP"}}
    creationTimestamp: "2025-07-30T21:04:55Z"
    labels:
      llm-d.ai/model: llama-3-2-1b
      llm-d.ai/role: decode
    name: llama-3-2-1b-decode-service
    namespace: llm-d
    resourceVersion: "4453598"
    uid: 175fc225-464e-4be9-b925-d58abc2989fb
  spec:
    clusterIP: 172.30.18.160
    clusterIPs:
    - 172.30.18.160
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: vllm
      port: 8000
      protocol: TCP
      targetPort: 8000
    - name: nixl
      port: 5557
      protocol: TCP
      targetPort: 5557
    selector:
      llm-d.ai/inferenceServing: "true"
      llm-d.ai/model: llama-3-2-1b
      llm-d.ai/role: decode
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
kind: List
metadata:
  resourceVersion: ""
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2025-08-04T18:10:45Z"
  labels:
    app.kubernetes.io/gateway: llm-d-operator-inference-gateway
    llm-d.ai/epp: llama-3-2-1b-epp
    llmd.ai/gather-metrics: "true"
  name: llama-3-2-1b-epp-service
  namespace: llm-d
  ownerReferences:
  - apiVersion: llm-d.ai/v1alpha1
    kind: ModelService
    name: llama-3-2-1b
    uid: f599ae32-471f-4469-8708-63f275563f9f
  resourceVersion: "11940372"
  uid: 6993babb-5781-4ff5-8dd1-7d2b48038788
spec:
  clusterIP: 172.30.9.138
  clusterIPs:
  - 172.30.9.138
  externalTrafficPolicy: Cluster
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: grpc
    nodePort: 32467
    port: 9002
    protocol: TCP
    targetPort: 9002
  - name: grpc-health
    nodePort: 32200
    port: 9003
    protocol: TCP
    targetPort: 9003
  - name: metrics
    nodePort: 30785
    port: 9090
    protocol: TCP
    targetPort: 9090
  selector:
    app.kubernetes.io/gateway: llm-d-operator-inference-gateway
    llm-d.ai/epp: llama-3-2-1b-epp
  sessionAffinity: None
  type: NodePort
status:
  loadBalancer: {}
