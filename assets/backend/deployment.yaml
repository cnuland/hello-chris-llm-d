apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: llm-d-backend
    component: backend
    part-of: llm-d-demo
  name: llm-d-backend
  namespace: llm-d
spec:
  replicas: 2
  selector:
    matchLabels:
      app: llm-d-backend
  template:
    metadata:
      labels:
        app: llm-d-backend
        component: backend
      annotations:
        sidecar.istio.io/inject: "false"
    spec:
      containers:
      - env:
        - name: NODE_ENV
          value: production
        - name: PORT
          value: "3001"
- name: LLM_SERVICE_URL
          value: "http://llama-3-2-3b-instruct-decode-service.llm-d.svc.cluster.local:8000"
        - name: EPP_SERVICE_URL
          value: "http://llama-3-2-3b-instruct-epp-service.llm-d.svc.cluster.local:9002"
        - name: PROMETHEUS_URL
          value: "http://prometheus-server.monitoring.svc.cluster.local:80"
        image: quay.io/cnuland/llm-interface:backend-amd64
        imagePullPolicy: Always
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        name: backend
        ports:
        - containerPort: 3001
          name: http
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
        resources:
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 200m
            memory: 256Mi
      restartPolicy: Always
