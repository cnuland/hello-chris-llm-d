#!/bin/bash

# Script to deploy enhanced cache-aware routing for >90% session stickiness
# This uses the ACTUAL cache-aware routing system with optimized EPP configuration
set -e

echo "üöÄ Deploying Enhanced Cache-Aware Routing"
echo "=========================================="
echo "This deployment optimizes the EPP (External Processing Pod) for:"
echo "  ‚Ä¢ Enhanced session-aware scoring with 20x weight"
echo "  ‚Ä¢ KV-cache-aware scoring with 10x weight" 
echo "  ‚Ä¢ Faster cache index updates (500ms intervals)"
echo "  ‚Ä¢ Session header recognition (session-id, x-session-id, authorization)"
echo "  ‚Ä¢ Optimized vLLM cache configuration"
echo ""

# Check if logged in
if ! kubectl get nodes >/dev/null 2>&1; then
    echo "‚ùå Not logged in to cluster. Please login first:"
    echo "   oc login ..."
    exit 1
fi

echo "‚úÖ Cluster access confirmed"

# Backup current configuration
echo "üì¶ Backing up current configuration..."
kubectl get configmap basic-gpu-with-hybrid-cache -n llm-d -o yaml > /tmp/backup-hybrid-cache-configmap.yaml 2>/dev/null || echo "No existing configmap to backup"
kubectl get modelservice llama-3-2-1b -n llm-d -o yaml > /tmp/backup-model-service.yaml 2>/dev/null || echo "No existing modelservice to backup"

# Deploy enhanced cache-aware routing configuration
echo "üì¶ Deploying enhanced cache-aware ConfigMap..."
kubectl apply -f assets/cache-aware/enhanced-cache-aware-configmap.yaml

# Update the existing ModelService to use the new ConfigMap
echo "üì¶ Updating ModelService to use enhanced cache-aware routing..."
kubectl patch modelservice llama-3-2-1b -n llm-d --type='merge' -p='{
  "spec": {
    "baseConfigMapRef": {
      "name": "basic-gpu-with-enhanced-cache-routing"
    }
  }
}'

# Wait for operator to reconcile
echo "‚è≥ Waiting for LLM-D operator to reconcile the changes..."
sleep 15

# Restart the operator to ensure it picks up the new configuration
echo "üîÑ Restarting LLM-D operator to force reconciliation..."
kubectl rollout restart deployment llm-d-operator-modelservice -n llm-d

# Wait for operator to restart
echo "‚è≥ Waiting for operator restart..."
kubectl rollout status deployment llm-d-operator-modelservice -n llm-d --timeout=120s

# Wait for new pods to be created
echo "‚è≥ Waiting for new enhanced pods to be deployed..."
sleep 30

# Check EPP configuration
echo "üîç Verifying EPP configuration..."
EPP_POD=$(kubectl get pods -n llm-d -l llm-d.ai/epp --no-headers -o custom-columns=":metadata.name" | head -1)
if [ -n "$EPP_POD" ]; then
    echo "EPP Pod: $EPP_POD"
    echo "Checking enhanced cache-aware routing configuration:"
    kubectl describe pod "$EPP_POD" -n llm-d | grep -A 20 "Environment:" | grep -E "(SESSION_AWARE_SCORER|KVCACHE_AWARE_SCORER|SESSION_HEADER_NAMES)" || echo "Configuration applied, checking logs..."
    
    # Check EPP logs for session-aware scoring
    echo "Checking EPP logs for session-aware scoring activation:"
    kubectl logs "$EPP_POD" -n llm-d --tail=10 | grep -i "session\|scorer\|routing" || echo "EPP is starting up, logs may not show routing details yet"
fi

# Check decode pods
echo "üîç Verifying decode pods configuration..."
DECODE_PODS=$(kubectl get pods -n llm-d -l llm-d.ai/role=decode --no-headers -o custom-columns=":metadata.name")
if [ -n "$DECODE_PODS" ]; then
    FIRST_DECODE_POD=$(echo "$DECODE_PODS" | head -1)
    echo "Sample decode pod: $FIRST_DECODE_POD"
    echo "Checking enhanced vLLM configuration:"
    kubectl describe pod "$FIRST_DECODE_POD" -n llm-d | grep -A 5 "Args:" | grep -E "(kv-cache-dtype|max-num-seqs|cache-index)" || echo "Enhanced vLLM config applied"
fi

# Verify pods are ready
echo "‚è≥ Waiting for all pods to be ready..."
kubectl wait --for=condition=ready pod -l llm-d.ai/role=decode -n llm-d --timeout=300s
kubectl wait --for=condition=ready pod -l llm-d.ai/epp -n llm-d --timeout=120s

echo "‚úÖ Enhanced cache-aware routing deployed successfully!"
echo ""
echo "üéØ Key enhancements applied:"
echo "   ‚Ä¢ Session-aware scoring: ENABLED with 20x weight"
echo "   ‚Ä¢ KV-cache-aware scoring: Enhanced to 10x weight"
echo "   ‚Ä¢ Session header recognition: session-id, x-session-id, authorization"
echo "   ‚Ä¢ Cache index updates: Faster (500ms intervals)"
echo "   ‚Ä¢ Session sticky duration: 3600 seconds (1 hour)"
echo "   ‚Ä¢ Enhanced vLLM batch processing and cache management"
echo ""
echo "üß™ Test with proper session headers:"
echo '   curl -H "session-id: enhanced-test-123" -H "Content-Type: application/json" \'
echo '        -d '"'"'{"model":"meta-llama/Llama-3.2-1B","prompt":"Hello world","max_tokens":10}'"'"' \'
echo '        https://llm-d-inference-gateway-llm-d.apps.rhoai-cluster.qhxt.p1.openshiftapps.com/v1/completions'
echo ""
echo "üìä Monitor with:"
echo "   ‚Ä¢ EPP logs: kubectl logs -f $EPP_POD -n llm-d"
echo "   ‚Ä¢ Decode pod metrics: kubectl exec <decode-pod> -n llm-d -c vllm -- curl localhost:8001/metrics"
echo ""
echo "üéâ Ready to test >90% cache-aware session stickiness!"
