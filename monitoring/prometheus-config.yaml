apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: llm-d-monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 5s
      evaluation_interval: 5s
      external_labels:
        cluster: 'llm-d'
        
    rule_files:
      - "/etc/prometheus/rules/*.yml"
      
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
      
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https
        
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
        
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - llm-d
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?:\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
        
    - job_name: 'llm-d-scheduler'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - llm-d
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: llm-d-scheduler
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: metrics
        
    - job_name: 'vllm-instances'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - llm-d
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_llm_d_ai_model]
        action: keep
        regex: 'llama-.*'
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: vllm
      - source_labels: [__address__]
        action: replace
        regex: '([^:]+):.*'
        replacement: '${1}:8000'
        target_label: __address__
      - source_labels: [__meta_kubernetes_service_label_llm_d_ai_role]
        action: replace
        target_label: vllm_role
      - source_labels: [__meta_kubernetes_service_label_llm_d_ai_model]
        action: replace
        target_label: vllm_model
        
    - job_name: 'envoy-gateway'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - envoy-gateway-system
          - llm-d
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: 'envoy-.*|.*gateway.*'
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: 'metrics|admin'
        
    - job_name: 'gateway-api-inference-extension'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - llm-d
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: '.*-epp-service'
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: 'metrics'
      - source_labels: [__address__]
        action: replace
        regex: '([^:]+):.*'
        replacement: '${1}:9090'
        target_label: __address__
      - source_labels: [__meta_kubernetes_service_label_llm_d_ai_epp]
        action: replace
        target_label: inference_extension
        
    - job_name: 'llm-d-components'
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - llm-d
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?:\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
  inference_rules.yml: |
    groups:
    - name: inference.rules
      rules:
      - alert: HighInferenceLatency
        expr: histogram_quantile(0.95, rate(vllm_request_duration_seconds_bucket[5m])) > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: High inference latency detected
          description: "95th percentile latency is {{ $value }}s for {{ $labels.instance }}"
          
      - alert: LowCacheHitRate
        expr: rate(vllm_cache_hit_total[5m]) / rate(vllm_cache_total[5m]) < 0.3
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Low cache hit rate
          description: "Cache hit rate is {{ $value | humanizePercentage }} for {{ $labels.instance }}"
          
      - alert: GPUMemoryHigh
        expr: vllm_gpu_memory_usage_bytes / vllm_gpu_memory_total_bytes > 0.9
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: GPU memory usage is high
          description: "GPU memory usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"
          
      - alert: InferenceQueueLengthHigh
        expr: vllm_queue_length > 20
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: High inference queue length
          description: "Queue length is {{ $value }} on {{ $labels.instance }}"
          
      - alert: SchedulerUnhealthy
        expr: up{job="llm-d-scheduler"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: llm-d scheduler is down
          description: "llm-d scheduler instance {{ $labels.instance }} is not responding"

